{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# download the data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "I am following this [Deep MNIST for Experts tutorial](https://www.tensorflow.org/versions/r0.11/tutorials/mnist/pros/index.html)\n",
    "\n",
    "## Know your data and terms\n",
    "\n",
    "Each data point has images and labels.\n",
    "\n",
    "### Images\n",
    "\n",
    "The images are called `xs`. They are the handwritten individual digits. \n",
    "\n",
    "#### Flattening\n",
    "\n",
    "The images are `flattened` which means that each pixel is represented by a floating point number representing how dark that pixel is (0 being white and .9 being black). \n",
    "\n",
    "The images are 28 pixels wide and 28 pixels tall, so in order to flatten the image we removed the 2D structure of it and just create an array of length 784 (784=28\\*28). This array is called a 784-dimensional vector space.\n",
    "\n",
    "### Labels\n",
    "\n",
    "The labels are called `ys`. They correspond to each image and identify what the digit really is.\n",
    "\n",
    "### Tensors\n",
    "\n",
    "A tensor is an n-dimensional array. In this case, `mnist.train.images` is a tensor that has dimensions `[55000, 784]` because we have 55,000 images, and each image is represented by a 784-dimensional vector (array, if you will).\n",
    "\n",
    "### One-Hot Vectors\n",
    "\n",
    "The labels are represented as one-hot vectors, which is a way of encoding a value in an array. For example, each of our labels is going to be one of the digits `0-9`. So, a one-hot vector for `0` is: `[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]` and a one-hot vector for `5` is: `[0, 0, 0, 0, 0, 1, 0, 0, 0, 0]`.\n",
    "\n",
    "The labels `mnist.train.labels` is a tensor that has dimensions `[55000, 10]` because we have 55,000 images, and each image has a one-hot vector that represents the label of that image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Know your model\n",
    "\n",
    "### Softmax Regression\n",
    "\n",
    "This tutorial uses softmax regression to classify what the digits are. For each image, it will give a probability of that image being a certain image. \"For example, our model might look at a picture of a nine and be 80% sure it's a nine, but give a 5% chance to it being an eight (because of the top loop) and a bit of probability to all the others because it isn't sure.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# initialize the variables\n",
    "init = tf.initialize_all_variables()\n",
    "# create an run the session\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Multilayer Convolutional Network\n",
    "\n",
    "An improved version of the above network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the wieghts have a small amount of noise so that it is not completely \n",
    "# symmetric which prevents 0 gradients too\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(\n",
    "        x,\n",
    "        ksize=[1, 2, 2, 1],\n",
    "        strides=[1, 2, 2, 1],\n",
    "        padding=\"SAME\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First Convolutional layer\n",
    "# the convolutional layer computes 32 features (32 output channels) for each\n",
    "# 5x5 patch, with 1 input channel\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Second Convolutional layer\n",
    "# this layer will computes 64 features (64 output channels) for each\n",
    "# 5x5 patch, with 32 input channels\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Deeply Connected Layer\n",
    "# the image size has been reduced to 7x7, this layer takes that as input\n",
    "# and processes it with 1024 neurons\n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "# this reshapes the tensor from the pooling layer into a batch of vectors\n",
    "# then multiplies by a weight matrix, adds a bias, and applies ReLU\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7 * 7 * 64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dropout\n",
    "# this reduces overfitting\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Softmax Regression\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 Training accuracy: 0.06\n",
      "Step: 100 Training accuracy: 0.88\n",
      "Step: 200 Training accuracy: 0.84\n",
      "Step: 300 Training accuracy: 0.98\n",
      "Step: 400 Training accuracy: 0.94\n",
      "Step: 500 Training accuracy: 0.94\n"
     ]
    }
   ],
   "source": [
    "# Training and Evaluating\n",
    "cross_entropy = tf.reduce_mean(\n",
    "    -tf.reduce_sum(y_ * tf.log(y_conv), reduction_indices=[1])\n",
    ")\n",
    "# this uses a different method of optimizing than above. The ADAM optimizer\n",
    "# is more sophisticated than the Gradient Descent Optimizer\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "sess.run(tf.initialize_all_variables())\n",
    "for i in range(20000):\n",
    "    batch = mnist.train.next_batch(50)\n",
    "    if i % 100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict= {\n",
    "                x: batch[0], y_: batch[1], keep_prob: 1.0\n",
    "            })\n",
    "        print(\"Step:\", i, \"Training accuracy:\", train_accuracy)\n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "print(\"Test accuracy: %g\"%accuracy.eval(feed_dict={\n",
    "            x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0\n",
    "        }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "git": {
   "suppress_output": true
  },
  "kernelspec": {
   "display_name": "Python [conda env:mnist-tf]",
   "language": "python",
   "name": "conda-env-mnist-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
