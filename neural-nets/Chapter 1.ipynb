{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks and Deep Learning\n",
    "\n",
    "These notes are taken from the [Neural Networks and Deep Learning online book](http://neuralnetworksanddeeplearning.com/) by [Michael Nielsen](http://michaelnielsen.org/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptrons\n",
    "One of the basic neurons is a perceptron, a perceptron is a function that takes inputs $ x_1, x_2, ..., x_n $ of $ \\{0, 1\\} $, with each input value having a corresponding weight value, $ w_1, w_2, ..., w_n $. \n",
    "The following function shows how the output is calculated: \n",
    "$$ \\begin{eqnarray}\n",
    "  \\mbox{output} & = & \\left\\{ \\begin{array}{ll}\n",
    "      0 & \\mbox{if } \\sum_j w_j x_j \\leq \\mbox{ threshold} \\\\\n",
    "      1 & \\mbox{if } \\sum_j w_j x_j > \\mbox{ threshold}\n",
    "      \\end{array} \\right.\n",
    "\\end{eqnarray} $$.\n",
    "\n",
    "Another way to write $ \\sum_j w_j x_j $ is $ w \\cdot x $. \n",
    "Another way to represent the `threshold` is with a `bias`, $ bias \\equiv -\\mbox{threshold} $.\n",
    "\n",
    "So the output function becomes: \n",
    "$$ \\begin{eqnarray}\n",
    "  \\mbox{output} = \\left\\{ \n",
    "    \\begin{array}{ll} \n",
    "      0 & \\mbox{if } w\\cdot x + b \\leq 0 \\\\\n",
    "      1 & \\mbox{if } w\\cdot x + b > 0\n",
    "    \\end{array}\n",
    "  \\right.\n",
    "\\end{eqnarray} $$.\n",
    "\n",
    "One can think of the bias as how easy it is to have the perceptron output a `1`. \n",
    "One can think of the weight as how important that input value should be considered; the higher the weight, the more important the input value is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid Neurons\n",
    "\n",
    "An advantage of sigmoid neurons over perceptrons is that a small change in the input value of a sigmoid neuron will result in a small change in the output value; unlike the behavior of a percpetron. \n",
    "This is so because the sigmoid neuron has a smoothing property baked in it.\n",
    "\n",
    "The first major difference between perceptrons and sigmoid functions is that sigmoid functions use floating point numbers as input and output, whereas perceptrons only use $ 0 $ and $ 1 $ for both input and output.\n",
    "\n",
    "Like the perceptron, the sigmoid neuron has inputs $ x_1, x_2, ..., x_n $, weights for each input $ w_1, w_2, ..., w_n $, and an overall bias $ b $.\n",
    "Unlike the perceptron, the function to calculate the output is $ \\sigma(w \\cdot x+b) $ such that:\n",
    "$$ \\begin{eqnarray} \n",
    "  \\sigma(z) \\equiv \\frac{1}{1+e^{-z}}.\n",
    "\\tag{3}\\end{eqnarray} $$\n",
    "\n",
    "$ \\sigma $ is called the sigmoid function or the logistic function.\n",
    "\n",
    "If $ z $ is a large positive number, then $ \\sigma(z) $ is going to be $ 1 $, or very close to it.\n",
    "If $ z $ is a very negative, then $ \\sigma(z) $ is going to be $ 0 $.\n",
    "\n",
    "In the beginning I said that sigmoid neurons allow a small change in $ \\Delta w_j $ would result in a small change in $ \\Delta output $. \n",
    "This is the function that proves that statement:\n",
    "$$ \\begin{eqnarray} \n",
    "  \\Delta \\mbox{output} \\approx \\sum_j \\frac{\\partial \\, \\mbox{output}}{\\partial w_j}\n",
    "  \\Delta w_j + \\frac{\\partial \\, \\mbox{output}}{\\partial b} \\Delta b,\n",
    "\\end{eqnarray} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost functions\n",
    "\n",
    "The cost function is sometimes referred to as a loss or objective function.\n",
    "The goal of the neural network is to minimize the value of the cost function.\n",
    "If the value of the cost function is high, then the neural network is not doing a good job at classifying the inputs.\n",
    "\n",
    "### Quadratic Cost Function\n",
    "For the MNIST dataset we will use a _quadratic_ cost function, also known as _mean squared error (MSE)_. \n",
    "The cost function is:\n",
    "$$ \\begin{eqnarray}  C(w,b) \\equiv\n",
    "  \\frac{1}{2n} \\sum_x \\| y(x) - a\\|^2.\n",
    "\\end{eqnarray} $$\n",
    "where $ w $ is the collection of all weights, $ b $ is the collection of all biases, $ n $ is the total number of training inputs, $ a $ is the vector of outputs from the network when $ x $ is the input, and the sum is over all training inputs, $ x $.\n",
    "$ \\| v \\| $ is the length function for a vector $ v $.\n",
    "\n",
    "It is noted that $ C(w,b) $ is non-negative because it is the sum of non-negative terms.\n",
    "The cost $ C(w,b) $ becomes small as $ y(x) $ becomes more equal to $ a $ for all training inputs, $ x $. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimization Techniques\n",
    "\n",
    "The goal of training the neural network is to minimize the cost function.\n",
    "An algorithm must be developed so that we can minimize this function.\n",
    "\n",
    "In the context of minimizing a function, we want to find the global minimum of some given function. \n",
    "A naieve approach to this problem would be to take the derivative of the function at different points and to find where the minimum is.\n",
    "This approach won't work when there are a large number of variables, like in a neural network.\n",
    "\n",
    "### _Gradient Descent_\n",
    "\n",
    "Imagine that a function represents a valley, and that we have an imaginary ball.\n",
    "Given that the ball starts at some random point, it is assumed that it will roll to the global minimum of the function.\n",
    "\n",
    "When the imaginary ball moves towards the minimum is represented mathematically by $ \\begin{eqnarray} \n",
    "  \\Delta C \\approx \\frac{\\partial C}{\\partial v_1} \\Delta v_1 +\n",
    "  \\frac{\\partial C}{\\partial v_2} \\Delta v_2.\n",
    "\\end{eqnarray} $. \n",
    "We want $ \\Delta C $ to be negative.\n",
    "In order to minimize $ \\Delta C $ we must change $ \\Delta v_1 $ and $ \\Delta v_2 $.\n",
    "Let $ \\Delta v \\equiv (\\Delta v_1, \\Delta v_2)^T $ where $ T $ is the transpose operation (transpose turns row vectors into column vectors).\n",
    "Let $ \\begin{eqnarray} \n",
    "  \\nabla C \\equiv \\left( \\frac{\\partial C}{\\partial v_1}, \n",
    "  \\frac{\\partial C}{\\partial v_2} \\right)^T.\n",
    "\\end{eqnarray} $, which leads to $ \\begin{eqnarray} \n",
    "  \\Delta C \\approx \\nabla C \\cdot \\Delta v.\n",
    "\\end{eqnarray} $.\n",
    "\n",
    "Now we can modify the equation to be $ \\Delta v = -\\eta \\nabla C $ so that $ \\nabla $ is a small, positive parameter and is known as the _learning rate_.\n",
    "Therefore, $ \\Delta C \\approx -\\eta \\nabla C \\cdot \\nabla C = -\\eta \\|\\nabla C\\|^2 $.\n",
    "We know that $ \\| \\nabla C \\|^2 \\geq 0 $ which means that $ \\Delta C \\leq 0 $, if $ v $ is changed in the right way.\n",
    "Each position of the imaginary ball is moved in such a manner: $ v \\rightarrow v' = v -\\eta \\nabla C $.\n",
    "\n",
    "The gradient descent algorithm computes the gradient $ \\nabla C $ and moves in the _opposite_ direction.\n",
    "In order for this to work properly, $ \\eta $ must not be too large or the imaginary ball will go past the minimum; $ \\eta $ must also not be too small  or the algorithm will be too slow.\n",
    "\n",
    "In the above equation, there were only two variables, but there can be more variables $ v_1, ..., v_m $ such that $ \\Delta v = (\\Delta v_1, ..., \\Delta v_m)^T $ and $ \\nabla C \\equiv \\left(\\frac{\\partial C}{\\partial v_1}, \\ldots, \\frac{\\partial C}{\\partial v_m}\\right)^T $.\n",
    "\n",
    "When we apply the gradient descent problem directly to neural networks, the equations are: \n",
    "$ w_k \\rightarrow w_k' = w_k-\\eta \\frac{\\partial C}{\\partial w_k} $ and $ b_l \\rightarrow b_l' = b_l-\\eta \\frac{\\partial C}{\\partial b_l} $.\n",
    "\n",
    "One issue is that this method is slow because the cost function is an average over the costs $ C_x \\equiv \\frac{\\|y(x)-a\\|^2}{2} $, which means that the gradient ends up being $ \\nabla C = \\frac{1}{n}\n",
    "\\sum_x \\nabla C_x $. The solutioin to this is to use _stochastic gradient descent_. \n",
    "\n",
    "### _Stochastic Gradient Descent_\n",
    "\n",
    "_Stochastic gradient descent_ calculates the gradient by randomly choosing a small sample from the inputs, and then averagin over that. Mathematically it chooses $ m $ random training inputs $ x_1, x_2, ..., x_m $ and is hereafter referred to as a _mini-batch_. This makes the assumption that $$  \\frac{\\sum_{j=1}^m \\nabla C_{X_{j}}}{m} \\approx \\frac{\\sum_x \\nabla C_x}{n} = \\nabla C $$.\n",
    "\n",
    "When this principle is directly applied to machine learning, it follows that $ w_k \\rightarrow w_k' = w_k-\\frac{\\eta}{m} \\sum_j \\frac{\\partial C_{X_j}}{\\partial w_k} $ and $ b_l \\rightarrow b_l' = b_l-\\frac{\\eta}{m} \\sum_j \\frac{\\partial C_{X_j}}{\\partial b_l} $. This process is repeated until all of the training inputs have been used. This process is called an _epoch_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def sigmoid(z):\n",
    "        return 1.0/(1.0+np.exp(-z))\n",
    "def sigmoid_prime(z):\n",
    "    return sigmoid(z) * (1 - sigmoid(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Network(object):\n",
    "    # @input sizes is a list with each index containing an integer that represents the\n",
    "    # number of neurons in that layer. Eg. [2, 3, 1] will create 2 neurons in the first\n",
    "    # layer, 3 neurons in the second layer, and 1 neuron in the third layer.\n",
    "    def __init__(self, sizes):\n",
    "        self.num_layers = len(sizes)\n",
    "        self.sizes = sizes\n",
    "        self.biases = [np.random.randn(y, 1) for y in sizes[1:]] # skips the first layer \n",
    "        # because it is an input layer\n",
    "        self.weights = [np.random.randn(y, x) for x, y in zip(sizes[:-1], sizes[1:])]\n",
    "    \n",
    "    # @input a is a Numpy ndarray of (n, 1)\n",
    "    def feedforward(self, a):\n",
    "        # Return the output of the network if a is input\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            a = sigmoid(np.dot(w, a) +b)\n",
    "        return a\n",
    "    \n",
    "    '''Trains the neural network using mini-batch stochastic gradient descent.\n",
    "    @input training_data is a list of tuples (x, y) that represent the training inputs\n",
    "    and the desired outputs.\n",
    "    @input epochs is the number of epochs to train.\n",
    "    @input mini_batch_size is the number of randomly selected inputs to use in an input.\n",
    "    @input eta is the learning rate.\n",
    "    @input test_data if provided, will evaluate the network after each epoch, slows things down.'''\n",
    "    def SGD(self, training_data, epochs, mini_batch_size, eta, test_data=None):\n",
    "        if test_data: n_test = len(test_data)\n",
    "        n = len(training_data)\n",
    "        for j in range(epochs):\n",
    "            random.shuffle(training_data)\n",
    "            mini_batches = [training_data[k:k + mini_batch_size] for k in range(0, n, mini_batch_size)]\n",
    "            for mini_batch in mini_batches:\n",
    "                self.update_mini_batch(mini_batch, eta) # applies gradient descent\n",
    "            if test_data:\n",
    "                print(\"Epoch\", j, \":\", self.evaluate(test_data), \"/\",  n_test)\n",
    "            else:\n",
    "                print(\"Epoch\", j, \"complete\")\n",
    "                \n",
    "    # Updates the network's weights and biases by applying backpropagation to a single \n",
    "    # mini-batch.\n",
    "    # @inputs mini_batch is a list of types (x, y).\n",
    "    # @input eta is the learning rate.\n",
    "    def update_mini_batch(self, mini_batch, eta):\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        for x, y in mini_batch:\n",
    "            delta_nabla_b, delta_nabla_w = self.backprop(x, y)\n",
    "            nabla_b = [nb + dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]\n",
    "            nabla_w = [nw + dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n",
    "        self.weights = [w - (eta / len(mini_batch)) * nw for w, nw in zip(self.weights, nabla_w)]\n",
    "        self.biases = [b - (eta / len(mini_batch)) * nb for b, nb in zip(self.biases, nabla_b)]\n",
    "        \n",
    "    def backprop(self, x, y):\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        \n",
    "        # feed forward\n",
    "        \n",
    "        activation = x\n",
    "        activations = [x]\n",
    "        zs = [] #store the z vectors, layer by layer\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            z = np.dot(w, activation) + b\n",
    "            zs.append(z)\n",
    "            activation = sigmoid(z)\n",
    "            activations.append(activation)\n",
    "        \n",
    "        # backward pass\n",
    "        delta = self.cost_derivative(activations[-1], y) * sigmoid_prime(zs[-1])\n",
    "        nabla_b[-1] = delta\n",
    "        nabla_w[-1] = np.dot(delta, activations[-2].transpose())\n",
    "        \n",
    "        for l in range(2, self.num_layers):\n",
    "            z = zs[-l]\n",
    "            sp = sigmoid_prime(z)\n",
    "            delta = np.dot(self.weights[-l + 1].transpose(), delta) * sp\n",
    "            nabla_b[-l] = delta\n",
    "            nabla_w[-l] = np.dot(delta, activations[-l - 1].transpose())\n",
    "        return (nabla_b, nabla_w)\n",
    "    \n",
    "    def evaluate(self, test_data):\n",
    "        test_results = [(np.argmax(self.feedforward(x)), y) for (x, y) in test_data]\n",
    "        return sum(int(x == y) for (x,y) in test_results)\n",
    "    \n",
    "    def cost_derivative(self, output_activations, y):\n",
    "        return (output_activations - y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import mnist_loader\n",
    "training_data, validation_data, test_data = mnist_loader.load_data_wrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = Network([784, 30, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 : 8292 / 10000\n",
      "Epoch 1 : 9198 / 10000\n",
      "Epoch 2 : 9268 / 10000\n",
      "Epoch 3 : 9355 / 10000\n",
      "Epoch 4 : 9382 / 10000\n",
      "Epoch 5 : 9415 / 10000\n",
      "Epoch 6 : 9421 / 10000\n",
      "Epoch 7 : 9451 / 10000\n",
      "Epoch 8 : 9471 / 10000\n",
      "Epoch 9 : 9485 / 10000\n",
      "Epoch 10 : 9482 / 10000\n",
      "Epoch 11 : 9505 / 10000\n",
      "Epoch 12 : 9502 / 10000\n",
      "Epoch 13 : 9494 / 10000\n",
      "Epoch 14 : 9502 / 10000\n",
      "Epoch 15 : 9494 / 10000\n",
      "Epoch 16 : 9499 / 10000\n",
      "Epoch 17 : 9460 / 10000\n",
      "Epoch 18 : 9488 / 10000\n",
      "Epoch 19 : 9487 / 10000\n",
      "Epoch 20 : 9501 / 10000\n",
      "Epoch 21 : 9494 / 10000\n",
      "Epoch 22 : 9519 / 10000\n",
      "Epoch 23 : 9504 / 10000\n",
      "Epoch 24 : 9520 / 10000\n",
      "Epoch 25 : 9498 / 10000\n",
      "Epoch 26 : 9521 / 10000\n",
      "Epoch 27 : 9495 / 10000\n",
      "Epoch 28 : 9511 / 10000\n",
      "Epoch 29 : 9535 / 10000\n"
     ]
    }
   ],
   "source": [
    "net.SGD(training_data, 30, 10, 3.0, test_data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
