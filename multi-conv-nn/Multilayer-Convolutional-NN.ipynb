{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# download the data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "I am following this [Deep MNIST for Experts tutorial](https://www.tensorflow.org/versions/r0.11/tutorials/mnist/pros/index.html)\n",
    "\n",
    "## Know your data and terms\n",
    "\n",
    "Each data point has images and labels.\n",
    "\n",
    "### Images\n",
    "\n",
    "The images are called `xs`. They are the handwritten individual digits. \n",
    "\n",
    "#### Flattening\n",
    "\n",
    "The images are `flattened` which means that each pixel is represented by a floating point number representing how dark that pixel is (0 being white and .9 being black). \n",
    "\n",
    "The images are 28 pixels wide and 28 pixels tall, so in order to flatten the image we removed the 2D structure of it and just create an array of length 784 (784=28\\*28). This array is called a 784-dimensional vector space.\n",
    "\n",
    "### Labels\n",
    "\n",
    "The labels are called `ys`. They correspond to each image and identify what the digit really is.\n",
    "\n",
    "### Tensors\n",
    "\n",
    "A tensor is an n-dimensional array. In this case, `mnist.train.images` is a tensor that has dimensions `[55000, 784]` because we have 55,000 images, and each image is represented by a 784-dimensional vector (array, if you will).\n",
    "\n",
    "### One-Hot Vectors\n",
    "\n",
    "The labels are represented as one-hot vectors, which is a way of encoding a value in an array. For example, each of our labels is going to be one of the digits `0-9`. So, a one-hot vector for `0` is: `[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]` and a one-hot vector for `5` is: `[0, 0, 0, 0, 0, 1, 0, 0, 0, 0]`.\n",
    "\n",
    "The labels `mnist.train.labels` is a tensor that has dimensions `[55000, 10]` because we have 55,000 images, and each image has a one-hot vector that represents the label of that image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Know your model\n",
    "\n",
    "### Softmax Regression\n",
    "\n",
    "This tutorial uses softmax regression to classify what the digits are. For each image, it will give a probability of that image being a certain image. \"For example, our model might look at a picture of a nine and be 80% sure it's a nine, but give a 5% chance to it being an eight (because of the top loop) and a bit of probability to all the others because it isn't sure.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# initialize the variables\n",
    "init = tf.initialize_all_variables()\n",
    "# create an run the session\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Multilayer Convolutional Network\n",
    "\n",
    "This network uses ReLU (Rectified Linear Unit) neurons, <https://en.wikipedia.org/wiki/Rectifier_(neural_networks)>, which are defined as: $$f(x) = max(0,x)$$\n",
    "Because of how we define the `weight` and `bias`, we are technically using Leaky ReLU's https://en.wikipedia.org/wiki/Rectifier_(neural_networks)#Leaky_ReLUs, which add a slight positive bias. The equation then becomes: $$f(x) = \\begin{cases} x, & \\mbox{if } x \\gt 0 \\\\ 0.1x, & \\mbox{otherwise} \\end{cases}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the wieghts have a small amount of noise so that it is not completely \n",
    "# symmetric which prevents 0 gradients too\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(\n",
    "        x,\n",
    "        ksize=[1, 2, 2, 1],\n",
    "        strides=[1, 2, 2, 1],\n",
    "        padding=\"SAME\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First Convolutional layer\n",
    "# the convolutional layer computes 32 features (32 output channels) for each\n",
    "# 5x5 patch, with 1 input channel\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Second Convolutional layer\n",
    "# this layer will computes 64 features (64 output channels) for each\n",
    "# 5x5 patch, with 32 input channels\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Deeply Connected Layer\n",
    "# the image size has been reduced to 7x7, this layer takes that as input\n",
    "# and processes it with 1024 neurons\n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "# this reshapes the tensor from the pooling layer into a batch of vectors\n",
    "# then multiplies by a weight matrix, adds a bias, and applies ReLU\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7 * 7 * 64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dropout\n",
    "# this reduces overfitting\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Softmax Regression\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 Training accuracy: 0.06\n",
      "Step: 100 Training accuracy: 0.88\n",
      "Step: 200 Training accuracy: 0.84\n",
      "Step: 300 Training accuracy: 0.98\n",
      "Step: 400 Training accuracy: 0.94\n",
      "Step: 500 Training accuracy: 0.94\n",
      "Step: 600 Training accuracy: 0.94\n",
      "Step: 700 Training accuracy: 0.98\n",
      "Step: 800 Training accuracy: 0.98\n",
      "Step: 900 Training accuracy: 0.98\n",
      "Step: 1000 Training accuracy: 0.94\n",
      "Step: 1100 Training accuracy: 0.9\n",
      "Step: 1200 Training accuracy: 0.98\n",
      "Step: 1300 Training accuracy: 1.0\n",
      "Step: 1400 Training accuracy: 0.96\n",
      "Step: 1500 Training accuracy: 0.94\n",
      "Step: 1600 Training accuracy: 1.0\n",
      "Step: 1700 Training accuracy: 0.96\n",
      "Step: 1800 Training accuracy: 0.96\n",
      "Step: 1900 Training accuracy: 0.96\n",
      "Step: 2000 Training accuracy: 0.98\n",
      "Step: 2100 Training accuracy: 0.98\n",
      "Step: 2200 Training accuracy: 1.0\n",
      "Step: 2300 Training accuracy: 0.98\n",
      "Step: 2400 Training accuracy: 0.98\n",
      "Step: 2500 Training accuracy: 1.0\n",
      "Step: 2600 Training accuracy: 0.96\n",
      "Step: 2700 Training accuracy: 1.0\n",
      "Step: 2800 Training accuracy: 1.0\n",
      "Step: 2900 Training accuracy: 1.0\n",
      "Step: 3000 Training accuracy: 0.98\n",
      "Step: 3100 Training accuracy: 1.0\n",
      "Step: 3200 Training accuracy: 0.98\n",
      "Step: 3300 Training accuracy: 1.0\n",
      "Step: 3400 Training accuracy: 1.0\n",
      "Step: 3500 Training accuracy: 1.0\n",
      "Step: 3600 Training accuracy: 1.0\n",
      "Step: 3700 Training accuracy: 0.98\n",
      "Step: 3800 Training accuracy: 1.0\n",
      "Step: 3900 Training accuracy: 0.98\n",
      "Step: 4000 Training accuracy: 1.0\n",
      "Step: 4100 Training accuracy: 1.0\n",
      "Step: 4200 Training accuracy: 0.98\n",
      "Step: 4300 Training accuracy: 0.96\n",
      "Step: 4400 Training accuracy: 1.0\n",
      "Step: 4500 Training accuracy: 1.0\n",
      "Step: 4600 Training accuracy: 1.0\n",
      "Step: 4700 Training accuracy: 0.98\n",
      "Step: 4800 Training accuracy: 1.0\n",
      "Step: 4900 Training accuracy: 1.0\n",
      "Step: 5000 Training accuracy: 1.0\n",
      "Step: 5100 Training accuracy: 1.0\n",
      "Step: 5200 Training accuracy: 1.0\n",
      "Step: 5300 Training accuracy: 1.0\n",
      "Step: 5400 Training accuracy: 1.0\n",
      "Step: 5500 Training accuracy: 0.98\n",
      "Step: 5600 Training accuracy: 1.0\n",
      "Step: 5700 Training accuracy: 1.0\n",
      "Step: 5800 Training accuracy: 0.98\n",
      "Step: 5900 Training accuracy: 0.98\n",
      "Step: 6000 Training accuracy: 1.0\n",
      "Step: 6100 Training accuracy: 1.0\n",
      "Step: 6200 Training accuracy: 0.98\n",
      "Step: 6300 Training accuracy: 1.0\n",
      "Step: 6400 Training accuracy: 0.94\n",
      "Step: 6500 Training accuracy: 1.0\n",
      "Step: 6600 Training accuracy: 1.0\n",
      "Step: 6700 Training accuracy: 1.0\n",
      "Step: 6800 Training accuracy: 0.98\n",
      "Step: 6900 Training accuracy: 1.0\n",
      "Step: 7000 Training accuracy: 1.0\n",
      "Step: 7100 Training accuracy: 0.98\n",
      "Step: 7200 Training accuracy: 1.0\n",
      "Step: 7300 Training accuracy: 1.0\n",
      "Step: 7400 Training accuracy: 0.98\n",
      "Step: 7500 Training accuracy: 1.0\n",
      "Step: 7600 Training accuracy: 0.96\n",
      "Step: 7700 Training accuracy: 1.0\n",
      "Step: 7800 Training accuracy: 0.98\n",
      "Step: 7900 Training accuracy: 0.98\n",
      "Step: 8000 Training accuracy: 0.98\n",
      "Step: 8100 Training accuracy: 1.0\n",
      "Step: 8200 Training accuracy: 1.0\n",
      "Step: 8300 Training accuracy: 1.0\n",
      "Step: 8400 Training accuracy: 0.98\n",
      "Step: 8500 Training accuracy: 0.98\n",
      "Step: 8600 Training accuracy: 1.0\n",
      "Step: 8700 Training accuracy: 1.0\n",
      "Step: 8800 Training accuracy: 1.0\n",
      "Step: 8900 Training accuracy: 1.0\n",
      "Step: 9000 Training accuracy: 1.0\n",
      "Step: 9100 Training accuracy: 0.98\n",
      "Step: 9200 Training accuracy: 1.0\n",
      "Step: 9300 Training accuracy: 1.0\n",
      "Step: 9400 Training accuracy: 0.98\n",
      "Step: 9500 Training accuracy: 1.0\n",
      "Step: 9600 Training accuracy: 1.0\n",
      "Step: 9700 Training accuracy: 1.0\n",
      "Step: 9800 Training accuracy: 1.0\n",
      "Step: 9900 Training accuracy: 0.98\n",
      "Step: 10000 Training accuracy: 1.0\n",
      "Step: 10100 Training accuracy: 1.0\n",
      "Step: 10200 Training accuracy: 1.0\n",
      "Step: 10300 Training accuracy: 1.0\n",
      "Step: 10400 Training accuracy: 1.0\n",
      "Step: 10500 Training accuracy: 0.98\n",
      "Step: 10600 Training accuracy: 0.98\n",
      "Step: 10700 Training accuracy: 0.96\n",
      "Step: 10800 Training accuracy: 1.0\n",
      "Step: 10900 Training accuracy: 1.0\n",
      "Step: 11000 Training accuracy: 1.0\n",
      "Step: 11100 Training accuracy: 1.0\n",
      "Step: 11200 Training accuracy: 1.0\n",
      "Step: 11300 Training accuracy: 1.0\n",
      "Step: 11400 Training accuracy: 1.0\n",
      "Step: 11500 Training accuracy: 1.0\n",
      "Step: 11600 Training accuracy: 1.0\n",
      "Step: 11700 Training accuracy: 1.0\n",
      "Step: 11800 Training accuracy: 1.0\n",
      "Step: 11900 Training accuracy: 1.0\n",
      "Step: 12000 Training accuracy: 1.0\n",
      "Step: 12100 Training accuracy: 1.0\n",
      "Step: 12200 Training accuracy: 0.98\n",
      "Step: 12300 Training accuracy: 1.0\n",
      "Step: 12400 Training accuracy: 1.0\n",
      "Step: 12500 Training accuracy: 1.0\n",
      "Step: 12600 Training accuracy: 1.0\n",
      "Step: 12700 Training accuracy: 1.0\n",
      "Step: 12800 Training accuracy: 1.0\n",
      "Step: 12900 Training accuracy: 1.0\n",
      "Step: 13000 Training accuracy: 1.0\n",
      "Step: 13100 Training accuracy: 0.98\n",
      "Step: 13200 Training accuracy: 1.0\n",
      "Step: 13300 Training accuracy: 1.0\n",
      "Step: 13400 Training accuracy: 1.0\n",
      "Step: 13500 Training accuracy: 1.0\n",
      "Step: 13600 Training accuracy: 1.0\n",
      "Step: 13700 Training accuracy: 1.0\n",
      "Step: 13800 Training accuracy: 1.0\n",
      "Step: 13900 Training accuracy: 1.0\n",
      "Step: 14000 Training accuracy: 1.0\n",
      "Step: 14100 Training accuracy: 1.0\n",
      "Step: 14200 Training accuracy: 1.0\n",
      "Step: 14300 Training accuracy: 1.0\n",
      "Step: 14400 Training accuracy: 1.0\n",
      "Step: 14500 Training accuracy: 1.0\n",
      "Step: 14600 Training accuracy: 1.0\n",
      "Step: 14700 Training accuracy: 1.0\n",
      "Step: 14800 Training accuracy: 1.0\n",
      "Step: 14900 Training accuracy: 1.0\n",
      "Step: 15000 Training accuracy: 1.0\n",
      "Step: 15100 Training accuracy: 1.0\n",
      "Step: 15200 Training accuracy: 1.0\n",
      "Step: 15300 Training accuracy: 1.0\n",
      "Step: 15400 Training accuracy: 1.0\n",
      "Step: 15500 Training accuracy: 1.0\n",
      "Step: 15600 Training accuracy: 1.0\n",
      "Step: 15700 Training accuracy: 1.0\n",
      "Step: 15800 Training accuracy: 1.0\n",
      "Step: 15900 Training accuracy: 1.0\n",
      "Step: 16000 Training accuracy: 1.0\n",
      "Step: 16100 Training accuracy: 1.0\n",
      "Step: 16200 Training accuracy: 1.0\n",
      "Step: 16300 Training accuracy: 1.0\n",
      "Step: 16400 Training accuracy: 1.0\n",
      "Step: 16500 Training accuracy: 1.0\n",
      "Step: 16600 Training accuracy: 1.0\n",
      "Step: 16700 Training accuracy: 1.0\n",
      "Step: 16800 Training accuracy: 1.0\n",
      "Step: 16900 Training accuracy: 1.0\n",
      "Step: 17000 Training accuracy: 0.98\n",
      "Step: 17100 Training accuracy: 1.0\n",
      "Step: 17200 Training accuracy: 1.0\n",
      "Step: 17300 Training accuracy: 1.0\n",
      "Step: 17400 Training accuracy: 1.0\n",
      "Step: 17500 Training accuracy: 1.0\n",
      "Step: 17600 Training accuracy: 1.0\n",
      "Step: 17700 Training accuracy: 1.0\n",
      "Step: 17800 Training accuracy: 1.0\n",
      "Step: 17900 Training accuracy: 1.0\n",
      "Step: 18000 Training accuracy: 1.0\n",
      "Step: 18100 Training accuracy: 1.0\n",
      "Step: 18200 Training accuracy: 1.0\n",
      "Step: 18300 Training accuracy: 1.0\n",
      "Step: 18400 Training accuracy: 1.0\n",
      "Step: 18500 Training accuracy: 1.0\n",
      "Step: 18600 Training accuracy: 1.0\n",
      "Step: 18700 Training accuracy: 1.0\n",
      "Step: 18800 Training accuracy: 1.0\n",
      "Step: 18900 Training accuracy: 1.0\n",
      "Step: 19000 Training accuracy: 1.0\n",
      "Step: 19100 Training accuracy: 1.0\n",
      "Step: 19200 Training accuracy: 1.0\n",
      "Step: 19300 Training accuracy: 1.0\n",
      "Step: 19400 Training accuracy: 1.0\n",
      "Step: 19500 Training accuracy: 1.0\n",
      "Step: 19600 Training accuracy: 1.0\n",
      "Step: 19700 Training accuracy: 1.0\n",
      "Step: 19800 Training accuracy: 1.0\n",
      "Step: 19900 Training accuracy: 1.0\n",
      "Test accuracy: 0.9933\n"
     ]
    }
   ],
   "source": [
    "# Training and Evaluating\n",
    "cross_entropy = tf.reduce_mean(\n",
    "    -tf.reduce_sum(y_ * tf.log(y_conv), reduction_indices=[1])\n",
    ")\n",
    "# this uses a different method of optimizing than above. The ADAM optimizer\n",
    "# is more sophisticated than the Gradient Descent Optimizer\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "sess.run(tf.initialize_all_variables())\n",
    "for i in range(20000):\n",
    "    batch = mnist.train.next_batch(50)\n",
    "    if i % 100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict= {\n",
    "                x: batch[0], y_: batch[1], keep_prob: 1.0\n",
    "            })\n",
    "        print(\"Step:\", i, \"Training accuracy:\", train_accuracy)\n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "print(\"Test accuracy: %g\"%accuracy.eval(feed_dict={\n",
    "            x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0\n",
    "        }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "git": {
   "suppress_output": true
  },
  "kernelspec": {
   "display_name": "Python [conda env:mnist-tf]",
   "language": "python",
   "name": "conda-env-mnist-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
